par(mfrow(2,2))
par(mfrow = c(2,2))
plot(bestmodel)
head(mtcars)
mtcars['Chrysler Imperial',]
mtcars['Toyota Corolla',]
mtcars['Fiat 128',]
summary(bestmodel)
basicmodel <- lm(mpg ~ amfact,           data = mtcars)
bestmodel  <- lm(mpg ~ amfact + wt + hp, data = mtcars)
fullmodel  <- lm(mpg ~ .,            data = mtcars)
anova(basicmodel, bestmodel, fullmodel)
summary(bestmodel)
?mtcars
cor(mtcars)
col <- colorRampPalette(c("blue", "white", "red"))(n = 299)
heatmap.2(cor(mtcars), col = col, symm = TRUE, trace = "none", density.info = "none")
knitr::opts_chunk$set(echo = TRUE)
library("gplots")
library("ggplot2")
library("car")
data(mtcars)
shapiro.test(mtcars$mpg)
amfact <- factor(mtcars$am, labels = c("Automatic", "Manual"))
mpgVam <- lm(mpg ~ amfact, data = mtcars)
summary(mpgVam)
cor(mtcars)[1,-1]
basicmodel <- lm(mpg ~ amfact,           data = mtcars)
bestmodel  <- lm(mpg ~ amfact + wt + hp, data = mtcars)
fullmodel  <- lm(mpg ~ .,            data = mtcars)
anova(basicmodel, bestmodel, fullmodel)
summary(bestmodel)
par(mfrow = c(1,2))
hist(mtcars$mpg, breaks = 20, col = "blue", xlab = "Miles per Gallon", main = "Figure 1: Histogram")
qqnorm(mtcars$mpg)
mtcars$am2 <- ifelse(mtcars$am == 0, "Automatic", "Manual")
boxplot(mpg ~ factor(am2), data = mtcars, col = c("blue", "darkred"), ylab = "Miles per Gallon", main = "Figure 2: Miles per Gallon vs Transmission Type")
col <- colorRampPalette(c("blue", "white", "red"))(n = 299)
heatmap.2(cor(mtcars), col = col, symm = TRUE, trace = "none", density.info = "none")
mtcars
boxplot(mpg ~ factor(amfact), data = mtcars, col = c("blue", "darkred"), ylab = "Miles per Gallon", main = "Figure 2: Miles per Gallon vs Transmission Type")
shapiro.test(mtcars$mpg)
mpgVam <- lm(mtcars$mpg ~ factor(mtcars$am, labels = c("Automatic", "Manual")), data = mtcars)
summary(mpgVam)$coef
levels(mtcars$am)
levels(mtcars$am)mtcars$am
mtcars$am
mtcars$am <- factor(mtcars$am, labels = c("Automatic", "Manual"))
mpgVam <- lm(mpg ~ am, data = mtcars)
summary(mpgVam)$coef
cor(mtcars)[1,-1]
as.numeric(mtcars)
mtcars
data(mtcars)
mtcars_cor <- cor(mtcars)
mtcars$am <- factor(mtcars$am, labels = c("Automatic", "Manual"))
mtcars$vs <- factor(mtcars$am, labels = c("V", "S"))
shapiro.test(mtcars$mpg)
mpgVam <- lm(mpg ~ am, data = mtcars)
summary(mpgVam)$coef
mtcars_cor[1,-1]
basicmodel <- lm(mpg ~ amfact,           data = mtcars)
bestmodel  <- lm(mpg ~ amfact + wt + hp, data = mtcars)
fullmodel  <- lm(mpg ~ .,                data = mtcars)
anova(basicmodel, bestmodel, fullmodel)
summary(bestmodel)$coef
anova(basicmodel, bestmodel, fullmodel)$coef
anova(basicmodel, bestmodel, fullmodel)$coef
names(anova(basicmodel, bestmodel, fullmodel))
anova(basicmodel, bestmodel, fullmodel)
par(mfrow = c(1,2))
hist(mtcars$mpg, breaks = 20, col = "blue", xlab = "Miles per Gallon", main = "Histogram")
qqnorm(mtcars$mpg)
boxplot(mpg ~ am, data = mtcars, col = c("blue", "darkred"), ylab = "Miles per Gallon", main = "Miles per Gallon vs Transmission Type")
col <- colorRampPalette(c("blue", "white", "red"))(n = 299)
heatmap.2(cor(mtcars), col = col, symm = TRUE, trace = "none", density.info = "none")
heatmap.2(mtcars_cor, col = col, symm = TRUE, trace = "none", density.info = "none")
par(mfrow = c(2,2))
plot(bestmodel)
heatmap.2(mtcars_cor, col = col, symm = TRUE, trace = "none", density.info = "none")
par(mfrow = c(2,2))
plot(bestmodel)
knitr::opts_chunk$set(echo = TRUE)
library("gplots")
library("ggplot2")
library("car")
data(mtcars)
mtcars_cor <- cor(mtcars)
mtcars$am <- factor(mtcars$am, labels = c("Automatic", "Manual"))
mtcars$vs <- factor(mtcars$am, labels = c("V", "S"))
mpgVam <- lm(mpg ~ am, data = mtcars)
summary(mpgVam)$coef
mtcars_cor[1,-1]
basicmodel <- lm(mpg ~ amfact,           data = mtcars)
bestmodel  <- lm(mpg ~ amfact + wt + hp, data = mtcars)
fullmodel  <- lm(mpg ~ .,                data = mtcars)
anova(basicmodel, bestmodel, fullmodel)
summary(bestmodel)$coef
par(mfrow = c(1,2))
hist(mtcars$mpg, breaks = 20, col = "blue", xlab = "Miles per Gallon", main = "Histogram")
qqnorm(mtcars$mpg)
boxplot(mpg ~ am, data = mtcars, col = c("blue", "darkred"), ylab = "Miles per Gallon", main = "Miles per Gallon vs Transmission Type")
col <- colorRampPalette(c("blue", "white", "red"))(n = 299)
heatmap.2(mtcars_cor, col = col, symm = TRUE, trace = "none", density.info = "none")
basicmodel <- lm(mpg ~ am,           data = mtcars)
bestmodel  <- lm(mpg ~ am + wt + hp, data = mtcars)
fullmodel  <- lm(mpg ~ .,            data = mtcars)
anova(basicmodel, bestmodel, fullmodel)
install.packages("rprojroot")
getOption("repos")
knitr::opts_chunk$set(echo = TRUE)
install.packages("TwitteR")
install.packages("twitteR")
library("twitteR")
setup_twitter_oauth("iNw4ThDyJpRhNR2w6ALYiVGss", "vmQVp7x2m856vR8Yke3xSiavfDz12QqQ79MeMmMMAfp1LKw2Vt")
setup_twitter_oauth("JVo8d80AQWEAAKfic1OiXfokX", "dxMpPipwwmZ54q7ZbDrJU2zO28PCaRbqZJGMXnLyZmrChSC9yz")
setup_twitter_oauth("JVo8d80AQWEAAKfic1OiXfokX", "dxMpPipwwmZ54q7ZbDrJU2zO28PCaRbqZJGMXnLyZmrChSC9yz")
install.packages("httpuv")
knitr::opts_chunk$set(echo = TRUE, message = FALSE, eval = TRUE)
install.packages("httr")
install.packages("httr")
knitr::opts_chunk$set(echo = TRUE, message = FALSE, eval = TRUE)
install.packages("httpuv")
library("twitteR")
setup_twitter_oauth("ipCk5LF25RvtiZ6Uxdg5KulfK", "XcZBujl1ReJXYE5fpYW3RCqddQAfo8P3hyVlo3s2tkmIIkKFVr")
?searchTwitter
searchTwitter("ultrarunning")
ultrarunning <- searchTwitter("ultrarunning", n = 10000)
length(ultrarunning)
ultra_running <- searchTwitter("ultra running", n = 10000)
length(ultra_running)
head(ultra_running)
ultrarunning  <- strip_retweets(searchTwitter("ultrarunning",  n = 10000), strip_manual=TRUE, strip_mt=TRUE)
length(ultrarunning)
head(ultrarunning)
ultra-running <- strip_retweets(searchTwitter("ultra-running", n = 10000), strip_manual=TRUE, strip_mt=TRUE)
length(ultra-running)
ultra__running <- strip_retweets(searchTwitter("ultra-running", n = 10000), strip_manual=TRUE, strip_mt=TRUE)
length(ultrarunning)
length(ultra_running)
length(ultra__running)
head(ultra__running)
head(ultra_running)
head(ultrarunning)
ultrarunning_tweets <- strip_retweets(searchTwitter("ultra+running",  n = 100), strip_manual=TRUE, strip_mt=TRUE)
ur_count <- NULL
for (t in c("ultrarunning", "ultra-running", "ultra running")) {
ur_count[[t]] <- length(grep(t, ultrarunning_tweets))
}
ur_count
class(ur_count)
ur_count <- NULL
for (t in c("ultrarunning", "ultra-running", "ultra running")) {
ur_count[[t]] <- length(grep(t, ultrarunning_tweets$getText))
}
ur_count
ultrarunning_tweets
ultrarunning_tweets$getText
class(ultrarunning_tweets)
class(searchTwitter("ultra+running",  n = 100))
names(ultrarunning_tweets)
getText(ultrarunning_tweets[[1]])
ultrarunning_tweets[[1]]$getText
ultrarunning_tweets[[1]]
class(ultrarunning_tweets[[1]])
test <- ultrarunning_tweets[[1]]
test$getText
test$getText()
ur_count <- NULL
for (t in c("ultrarunning", "ultra-running", "ultra running")) {
ur_count[[t]] <- length(grep(t, sapply(ultrarunning_tweets, FUN = function (x) x$getText())))
}
ur_count
sapply(ultrarunning_tweets, FUN = function (x) x$getText())
length(ultrarunning_tweets)
rm(ultrarunning_tweets)
numtweets <- 100                                                                  ## Number of tweets to access
ur_tweets_all  <- searchTwitter("ultra+running",  n = numtweets)                  ## Get tweets
ur_tweets_trim <- strip_retweets(ur_tweets_all, strip_manual=TRUE, strip_mt=TRUE) ## Trim retweets
get(ur_tweets_trim, "Text")
get(ur_tweets_trim, Text)
get(ur_tweets_trim, "text")
slotNames(ur_tweets_trim)
slotNames(ur_tweets_trim)
names(ur_tweets_trim)
str(ur_tweets_trim)
get(ur_tweets_trim, "text")
get(ur_tweets_trim[[1]], "text")
get(ur_tweets_trim[[1]], "Text")
str(ur_tweets_trim[[1]])
gettext(ur_tweets_trim[[1]])
gettext(ur_tweets_trim)
getText(ur_tweets_trim)
getText(ur_tweets_trim[[1]])
ur_tweets_trim[[1]]$getText()
ur_tweets_trim$getText()
ur_tweets_text <- twListToDf(ur_tweets_trim)
ur_tweets_text <- twListToDF(ur_tweets_trim)
ur_tweets_text
ur_tweets_text <- twListToDF(ur_tweets_trim)
ur_tweets_text
ur_tweets_text <- sapply(ur_tweets_trim, function (x) x$getText())
ur_tweets_text
ur_count <- NULL
for (t in c("ultrarunning", "ultra-running", "ultra running")) {
ur_count[[t]] <- length(grep(t, ur_tweets_text))
}
ur_count
t
umtweets <- 1000                                                                 ## Number of tweets to access
ur_tweets_all  <- searchTwitter("ultra+running",  n = numtweets)                  ## Get tweets
ur_tweets_trim <- strip_retweets(ur_tweets_all, strip_manual=TRUE, strip_mt=TRUE) ## Trim retweets
ur_tweets_text <- sapply(ur_tweets_trim, function (x) x$getText())                ## Get the status text
ur_count <- NULL
for (t in c("ultrarunning", "ultra-running", "ultra running")) {
ur_count[[t]] <- length(grep(t, ur_tweets_text))
}
ur_count
length(ur_tweets_trim)
ur_tweets_trim
ur_tweets_all  <- searchTwitter("ultra AND running",  n = numtweets)                  ## Get tweets
ur_tweets_all
?searchTwitter
ur_tweets_all  <- searchTwitter("ultra+running+ultrarunning+ultra-running",  n = numtweets, resultType = "recent")                  ## Get tweets
ur_tweets_all
numtweets <- 1000                                                                 ## Number of tweets to access
ur_tweets_all  <- searchTwitter("ultra+running+ultrarunning+ultra-running",  n = numtweets, resultType = "recent")                  ## Get tweets
ur_tweets_trim <- strip_retweets(ur_tweets_all, strip_manual=TRUE, strip_mt=TRUE) ## Trim retweets
ur_tweets_text <- sapply(ur_tweets_trim, function (x) x$getText())                ## Get the status text
ur_count <- NULL
for (t in c("ultrarunning", "ultra-running", "ultra running")) {
ur_count[[t]] <- length(grep(t, ur_tweets_text))
}
ur_count
ur_tweets_trim
ur_count <- NULL
for (t in c("ultrarunning", "ultra\\s?-\\srunning", "ultra\\s+running")) {
ur_count[[t]] <- length(grep(t, ur_tweets_text))
}
ur_count
ur_count <- NULL
for (t in c("ultrarunning", "ultra\\s?-\\s?running", "ultra\\s+running")) {
ur_count[[t]] <- length(grep(t, ur_tweets_text))
}
ur_count
ur_count <- NULL
for (t in c("ultrarunning", "ultra-running", "ultra running")) {
ur_count[[t]] <- length(grep(t, ur_tweets_text))
}
ur_count
pie(ur_count)
?pie
pie(ur_count, col = c("grey90","grey50","black"))
library("twitteR")
numtweets <- 10000
ur_tweets_all  <- searchTwitter("ultra+running+ultrarunning+ultra-running",  n = numtweets)
ur_tweets_trim <- strip_retweets(ur_tweets_all, strip_manual=TRUE, strip_mt=TRUE)
ur_tweets_text <- sapply(ur_tweets_trim, function (x) x$getText())
ur_count <- NULL
for (t in c("ultrarunning", "ultra-running", "ultra running")) {
ur_count[[t]] <- length(grep(t, ur_tweets_text))
}
ur_count
ur_tweets_all  <- searchTwitter("ultra+runner+ultrarunner+ultra-runner",  n = numtweets)
ur_tweets_all
ur_tweets_all  <- searchTwitter("ultra+marathon+ultramarathon+ultra-marathon",  n = numtweets)
ur_tweets_trim <- strip_retweets(ur_tweets_all, strip_manual=TRUE, strip_mt=TRUE)
ur_tweets_text <- sapply(ur_tweets_trim, function (x) x$getText())
ur_count <- NULL
for (t in c("ultrarunning", "ultra-running", "ultra running")) {
ur_count[[t]] <- length(grep(t, ur_tweets_text))
}
ur_count
ur_tweets_text
ur_count <- NULL
for (t in c("ultramarathon", "ultra-marathon", "ultra marathon")) {
ur_count[[t]] <- length(grep(t, ur_tweets_text))
}
ur_count
library("tm")
install.packages("tm")
library("tm")
library("wordcloud")
install.packages("wordcloud")
library("tm")
library("wordcloud")
cloud_dat <- Corpus(VectorSource(ur_tweets_text))
cloud_dat
cloud_dat <- Corpus(VectorSource(ur_tweets_text))
cloud_dat <- tm_map(cloud_dat, PlainTextDocument)
cloud_dat <- tm_map(cloud_dat, removePunctuation)
cloud_dat <- tm_map(cloud_dat, removeWords)
cloud_dat <- tm_map(cloud_dat,stemDocument)
?stopwords
?tm_map
library("SnowballC")
install.packages("SnowballC")
library("SnowballC")
cloud_dat <- Corpus(VectorSource(ur_tweets_text))
cloud_dat <- tm_map(cloud_dat, PlainTextDocument)
cloud_dat <- tm_map(cloud_dat, content_transformer(tolower))
cloud_dat <- tm_map(cloud_dat, removePunctuation)
cloud_dat <- tm_map(cloud_dat, removeWords)
cloud_dat <- tm_map(cloud_dat,stemDocument)
?removeWords
cloud_dat <- tm_map(cloud_dat, removeWords, stopwords("english"))
cloud_dat <- Corpus(VectorSource(ur_tweets_text))
cloud_dat <- tm_map(cloud_dat, PlainTextDocument)
cloud_dat <- tm_map(cloud_dat, content_transformer(tolower))
cloud_dat <- tm_map(cloud_dat, removePunctuation)
cloud_dat <- tm_map(cloud_dat, removeWords, stopwords("english"))
cloud_dat <- tm_map(cloud_dat,stemDocument)
wordcloud(cloud_dat)
cloud_dat
ur_tweets_text
library("twitteR")
numtweets <- 1000
ur_tweets_all  <- searchTwitter("ultra+running+ultrarunning+ultra-running",  n = numtweets)
ur_tweets_trim <- strip_retweets(ur_tweets_all, strip_manual=TRUE, strip_mt=TRUE)
ur_tweets_text <- sapply(ur_tweets_trim, function (x) x$getText())
ur_count <- NULL
for (t in c("ultrarunning", "ultra-running", "ultra running")) {
ur_count[[t]] <- length(grep(t, ur_tweets_text))
}
pie(ur_count, col = c("grey90","grey50","black"))
library("tm")
library("wordcloud")
library("SnowballC")
cloud_dat <- Corpus(VectorSource(ur_tweets_text))
cloud_dat <- tm_map(cloud_dat, PlainTextDocument)
cloud_dat <- tm_map(cloud_dat, content_transformer(tolower))
cloud_dat <- tm_map(cloud_dat, removePunctuation)
cloud_dat <- tm_map(cloud_dat, removeWords, stopwords("english"))
cloud_dat <- tm_map(cloud_dat,stemDocument)
wordcloud(cloud_dat)
ur_tweets_text
ur_tweets_all  <- searchTwitter("ultra+running+ultrarunning",  n = numtweets)
ur_tweets_all  <- searchTwitter("ultra",  n = numtweets)
ur_tweets_trim <- strip_retweets(ur_tweets_all, strip_manual=TRUE, strip_mt=TRUE)
ur_tweets_text <- sapply(ur_tweets_trim, function (x) x$getText())
length(ur_tweets_text)
head(ur_tweets_text)
ur_tweets_text <- ur_tweets_text[grep("ultrarunning|ultra\\srunning|ultra-running")]
ur_tweets_text <- ur_tweets_text[grep("ultrarunning|ultra\\srunning|ultra-running", ur_tweets_text)]
length(ur_tweets_text)
ur_tweets_trim <- strip_retweets(ur_tweets_all, strip_manual=TRUE, strip_mt=TRUE)
ur_tweets_text <- sapply(ur_tweets_trim, function (x) x$getText())
class(ur_tweets_text)
head(ur_tweets_text)
grep("ultrarunning", ur_tweets_text)
grep("ultra", ur_tweets_text)
grep("ultra", ur_tweets_text, ignore.case = TRUE)
ur_tweets_all  <- searchTwitter("ultrarun",  n = numtweets)
ur_tweets_all  <- searchTwitter("ultramarathon",  n = numtweets)
ur_tweets_all  <- searchTwitter("ultramarathon+ultra marathon",  n = numtweets)
ur_tweets_all  <- searchTwitter("ultramarathon|ultra marathon",  n = numtweets)
head(ur_tweets_all)
ur_tweets_all  <- searchTwitter("ultrarunning",  n = numtweets)
ur_tweets_all  <- searchTwitter("ultrarunning|ultra running",  n = numtweets)
ur_tweets_trim <- strip_retweets(ur_tweets_all, strip_manual=TRUE, strip_mt=TRUE)
ur_tweets_text <- sapply(ur_tweets_trim, function (x) x$getText())
ur_tweets_text <- ur_tweets_text[grep("ultrarunning|ultra\\srunning|ultra-running", ur_tweets_text, ignore.case = TRUE)]
ur_count <- NULL
for (t in c("ultrarunning", "ultra-running", "ultra running")) {
ur_count[[t]] <- length(grep(t, ur_tweets_text))
}
ur_count
length(ur_tweets_trim)
length(ur_tweets_all)
(100*1-(length(ur_tweets_trim)/length(ur_tweets_all)))
length(ur_tweets_all)
length(ur_tweets_trim)
100*(1-(length(ur_tweets_trim)/length(ur_tweets_all)))
numtweets      <- 10000
ur_tweets_all  <- searchTwitter("ultrarunning|ultra running",  n = numtweets)
ur_tweets_trim <- strip_retweets(ur_tweets_all, strip_manual=TRUE, strip_mt=TRUE)
ur_tweets_text <- sapply(ur_tweets_trim, function (x) x$getText())
ur_tweets_text <- ur_tweets_text[grep("ultrarunning|ultra\\srunning|ultra-running", ur_tweets_text, ignore.case = TRUE)]
ur_count <- NULL
for (t in c("ultrarunning", "ultra-running", "ultra running")) {
ur_count[[t]] <- length(grep(t, ur_tweets_text))
}
ur_count
length(ur_tweets_all)
length(ur_tweets_trim)
100*(1-(length(ur_tweets_trim)/length(ur_tweets_all)))
ur_tweets_trim <- strip_retweets(ur_tweets_all, strip_manual=TRUE, strip_mt=TRUE)
ur_tweets_text <- sapply(ur_tweets_trim, function (x) x$getText())
ur_tweets_text <- ur_tweets_text[grep("ultrarunning|ultra running|ultra-running", ur_tweets_text, ignore.case = TRUE)]
ur_count <- NULL
for (t in c("ultrarunning", "ultra-running", "ultra running")) {
ur_count[[t]] <- length(grep(t, ur_tweets_text))
}
length(ur_tweets_all)
length(ur_tweets_trim)
length(ur_tweets_text)
ur_tweets_text <- sapply(ur_tweets_trim, function (x) x$getText())
ur_tweets_text <- ur_tweets_text[grep("ultrarunning|ultra\\srunning|ultra-running", ur_tweets_text, ignore.case = TRUE)]
length(ur_tweets_text)
numtweets      <- 1000000
ur_tweets_all  <- searchTwitter("ultrarunning|ultra running",  n = numtweets)
ur_tweets_trim <- strip_retweets(ur_tweets_all, strip_manual=TRUE, strip_mt=TRUE)
ur_tweets_text <- sapply(ur_tweets_trim, function (x) x$getText())
ur_tweets_text <- ur_tweets_text[grep("ultrarunning|ultra\\srunning|ultra-running", ur_tweets_text, ignore.case = TRUE)]
ur_count <- NULL
for (t in c("ultrarunning", "ultra-running", "ultra running")) {
ur_count[[t]] <- length(grep(t, ur_tweets_text, ignore.case = TRUE))
}
ur_counts
ur_count
length(ur_tweets_text)
ur_tweets_text <- sapply(ur_tweets_trim, function (x) x$getText())
ur_tweets_text <- ur_tweets_text[grep("ultrarunning|ultra running|ultra-running", ur_tweets_text, ignore.case = TRUE)]
length(ur_tweets_text)
head(ur_tweets_trim)
numtweets      <- 1000000
ur_tweets_all  <- searchTwitter("ultramarathon|ultra marathon",  n = numtweets)
ur_tweets_trim <- strip_retweets(ur_tweets_all, strip_manual=TRUE, strip_mt=TRUE)
ur_tweets_text <- sapply(ur_tweets_trim, function (x) x$getText())
ur_tweets_text <- ur_tweets_text[grep("ultramarathon|ultra marathon|ultra-marathon", ur_tweets_text, ignore.case = TRUE)]
ur_count <- NULL
for (t in c("ultramarathon", "ultra-marathon", "ultra marathon")) {
ur_count[[t]] <- length(grep(t, ur_tweets_text, ignore.case = TRUE))
}
ur_count
length(ur_tweets_all)
length(ur_tweets_trim)
length(ur_tweets_text)
pie(ur_count, col = c("grey90","grey50","black"))
um_tweets_text <- ur_tweets_text
um_count <- ur_count
um_tweets_all <- ur_tweets_all
um_tweets_trim <- ur_tweets_trim
ur_tweets_all  <- searchTwitter("ultrarunning|ultra running",  n = numtweets)
ur_tweets_trim <- strip_retweets(ur_tweets_all, strip_manual=TRUE, strip_mt=TRUE)
ur_tweets_text <- sapply(ur_tweets_trim, function (x) x$getText())
ur_tweets_text <- ur_tweets_text[grep("ultrarunning|ultra running|ultra-running", ur_tweets_text, ignore.case = TRUE)]
ur_count <- NULL
for (t in c("ultrarunning", "ultra-running", "ultra running")) {
ur_count[[t]] <- length(grep(t, ur_tweets_text, ignore.case = TRUE))
}
ur_count
um_count
length(ur_tweets_all)
length(ur_tweets_trim)
length(ur_tweets_text)
length(um_tweets_text)
pie(ur_count, col = c("grey90","grey50","black"))
cloud_dat <- Corpus(VectorSource(c(um_tweets_text, ur_tweets_text))) ## Create Corpus
cloud_dat <- tm_map(cloud_dat, PlainTextDocument)                    ## Make plain text
cloud_dat <- tm_map(cloud_dat, content_transformer(tolower))         ## Convert to lower case
cloud_dat <- tm_map(cloud_dat, removePunctuation)                    ## Remove punctuation
cloud_dat <- tm_map(cloud_dat, removeWords, stopwords("english"))    ## Remove common English words
cloud_dat <- tm_map(cloud_dat, stemDocument)                         ## Convert all words to their stem
wordcloud(cloud_dat)
encoding(um_tweets_text)
Encoding(um_tweets_text)
Encoding(um_tweets_text) <- "UTF-8"
Encoding(ur_tweets_text) <- "UTF-8"
um_tweets_text
cloud_dat <- Corpus(VectorSource(c(um_tweets_text, ur_tweets_text))) ## Create Corpus
cloud_dat <- tm_map(cloud_dat, PlainTextDocument)                    ## Make plain text
cloud_dat <- tm_map(cloud_dat, content_transformer(tolower))         ## Convert to lower case
cloud_dat <- tm_map(cloud_dat, removePunctuation)                    ## Remove punctuation
cloud_dat <- tm_map(cloud_dat, removeWords, stopwords("english"))    ## Remove common English words
cloud_dat <- tm_map(cloud_dat, stemDocument)                         ## Convert all words to their stem
ur_tweets_text <- sapply(ur_tweets_trim, function (x) x$getText())
ur_tweets_text <- ur_tweets_text[grep("ultrarunning|ultra running|ultra-running", ur_tweets_text, ignore.case = TRUE)]
um_tweets_text <- sapply(um_tweets_trim, function (x) x$getText())
um_tweets_text <- um_tweets_text[grep("ultramarathon|ultra marathon|ultra-marathon", um_tweets_text, ignore.case = TRUE)]
all_tweets <- c(ur_tweets_text, um_tweets_text)
all_tweets <- c(ur_tweets_text, um_tweets_text)
all_tweets <- iconv(all_tweets, "latin1", "ASCII", sub = "")
all_tweets
all_tweets <- c(ur_tweets_text, um_tweets_text)
all_tweets <- iconv(all_tweets, "latin1", "ASCII", sub = "")         ## Convert encodings
cloud_dat <- Corpus(VectorSource(all_tweets))                        ## Create Corpus
cloud_dat <- tm_map(cloud_dat, PlainTextDocument)                    ## Make plain text
cloud_dat <- tm_map(cloud_dat, content_transformer(tolower))         ## Convert to lower case
cloud_dat <- tm_map(cloud_dat, removePunctuation)                    ## Remove punctuation
cloud_dat <- tm_map(cloud_dat, removeWords, stopwords("english"))    ## Remove common English words
cloud_dat <- tm_map(cloud_dat, stemDocument)                         ## Convert all words to their stem
wordcloud(cloud_dat)
wordcloud(cloud_dat, max.words = 100, min.freq = 10, random.order = TRUE)
wordcloud(cloud_dat, max.words = 1000, min.freq = 10, random.order = TRUE)
wordcloud(cloud_dat, max.words = 1000, min.freq = 5, random.order = TRUE)
wordcloud(cloud_dat, max.words = 1000, min.freq = 5, random.order = TRUE, colors = "Reds")
wordcloud(cloud_dat, max.words = 1000, min.freq = 5, random.order = TRUE, colors = "Dark2")
?wordcloud
wordcloud(cloud_dat, max.words = 1000, min.freq = 5, random.order = FALSE, colors = "Dark2")
wordcloud(cloud_dat, max.words = 1000, min.freq = 5, random.order = FALSE)
all_tweets <- c(ur_tweets_text, um_tweets_text)
all_tweets <- iconv(all_tweets, "latin1", "ASCII", sub = "")         ## Convert encodings
cloud_dat <- Corpus(VectorSource(all_tweets))                        ## Create Corpus
cloud_dat <- tm_map(cloud_dat, PlainTextDocument)                    ## Make plain text
cloud_dat <- tm_map(cloud_dat, content_transformer(tolower))         ## Convert to lower case
cloud_dat <- tm_map(cloud_dat, removePunctuation)                    ## Remove punctuation
cloud_dat <- tm_map(cloud_dat, removeWords, stopwords("english"))    ## Remove common English words
wordcloud(cloud_dat, max.words = 1000, min.freq = 5, random.order = FALSE)
wordcloud(cloud_dat, max.words = 1000, min.freq = 5, random.order = FALSE, colors = brewer.pal(8, "BuGn"))
wordcloud(cloud_dat, max.words = 1000, min.freq = 5, random.order = FALSE, colors = brewer.pal(9, "BuGn")[-(1:4)])
wordcloud(cloud_dat, max.words = 1000, min.freq = 5, random.order = FALSE, colors = brewer.pal(9, "Reds")[-(1:4)])
wordcloud(cloud_dat, max.words = 1000, min.freq = 5, random.order = FALSE, colors = brewer.pal(9, "PRGn")[-(1:4)])
wordcloud(cloud_dat, max.words = 1000, min.freq = 5, random.order = FALSE, colors = brewer.pal(9, "PRGn")
)
wordcloud(cloud_dat, max.words = 1000, min.freq = 5, random.order = FALSE, colors = brewer.pal(9, "ReBu"))
wordcloud(cloud_dat, max.words = 1000, min.freq = 5, random.order = FALSE, colors = brewer.pal(9, "RdBu"))
wordcloud(cloud_dat, max.words = 1000, min.freq = 10, random.order = FALSE, colors = brewer.pal(9, "RdBu")
)
wordcloud(cloud_dat, max.words = 1000, min.freq = 5, random.order = FALSE, colors = brewer.pal(9, "RdBu"))
um_count
ur_count
