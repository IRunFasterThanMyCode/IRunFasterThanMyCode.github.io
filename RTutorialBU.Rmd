---
layout: page
comments: true
title: "R Tutorial"
author: Sam Robson
tags: R, tutorial 
permalink: /tutorial/
---

# How to use R

This tutorial is a basic introduction to R. R is a software package
that is a free to use open-source version of the S programming
language. It is designed mainly for running statistical analyses and
is very powerful in this regard. Follow through the tutorial and run
the example commands by typing them into the command line as you go to
see what happens. Don't be afraid to play around with things as you go
-- it's the best way to find out what certain functions do.  

You will notice that I have added comments to some of the code using
the ``\#'' comment character. Everything to the right of this character
is ignored by R. This can be used to add comments to your code, for
instance to explain what a particular code chunk does. You can NEVER
have too many comments! 


## Installing R

First of all, you will need to download and install R. The R website
can be found at
\href{http://www.r-project.org}{http://www.r-project.org}. R is
updated quite regularly -- there is an updated release roughly every 6 months,
with various developmental versions released between the official
versions. The functions in R are actively maintained to ensure that
they run as they should, and new functionality is added all of the
time.  

The current version is 2.13.1. To download it, go to
\href{http://www.stats.bris.ac.uk/R/}{http://www.stats.bris.ac.uk/R/}. 
There are ready-made binaries
available for MAC, so follow the links and download the file
R-2.13.1.pkg as instructed.  

Once it has downloaded, double click on the file and follow the
prompts to install the R environment. 


## Basics of R
### Introduction
Open the R environment. This is a command line version allowing you to
see the results of the commands that you enter as you run them. 

The command line is shown by the ``$>$'' character. Simply type your
command here and press return to see the results. If your command is
not complete, then the command line character will change to a ``+'' to
indicate that more input is required, for instance a missing
parenthesis: 

\begin{lstlisting}
print ("Hello World!" # Final parenthesis missing - CTRL+c or ESC to end
\end{lstlisting}

R stores ``variables'' using names made up of characters and numbers. A
variable, as the name suggests, is a data ``object'' that can take any
value that you want, and can be changed.  

The variable name can be anything that you like (although it must
begin with a character), and I recommend naming variables with a name
that describes what the variable is (e.g. ``patient\_height'' instead of
``x''). 

To assign a value to the variable, use the ``$<$-'' command (less-than
symbol followed by minus symbol). You can also use the ``='' symbol, but
this has other uses so I prefer to use the ``$<$-'' command: 
 
\begin{lstlisting}
x <- 3
x # Returns the value stored in 'x'
x <- 5
x
\end{lstlisting}

Simple arithmetic can be performed using the standard arithmetic
operators ('\verb:+:', '\verb:-:', '\verb:*:', '\verb:/:'), as well as the exponent operator
('\verb:^:'). There is a level of precedence to these functions - the
exponent will be calculated first, followed by multiplication and
division, followed by plus and minus. For this reason, you must be
careful that your arithmetic is doing what you expect it to do. You
can get around this by encapsulating subsets of the sum in
parentheses, which will be calculated from the inside out: 

\begin{lstlisting}
x <-  1 + 2 * 3  # Equals 7
x
y <- (1 + 2) * 3 # Equals 9
y
z <- 1 + (2 * 3) # Equals 7
z
\end{lstlisting}

You can NEVER have too many parentheses - they ensure that your
equations are doing what they should, and they can help improve the
readability of things making it easier to see what a calculation is
trying to achieve. 

Another operator that you may not have seen before is the ``modulo''
operator (``\%\%''), which gives you the remainder left after dividing by
the number: 

\begin{lstlisting}
6%%2 # 6 is divisible by 2 exactly three times, so the remainder is 0
6%%4 # 6 is divisible by 4 one time with a remainder of 2
\end{lstlisting}

You can also use other variables in these assignments:

\begin{lstlisting}
x <- 1
y <- x
y
z <- x + y
z
\end{lstlisting}

### Data Classes

Variables can take many forms, or ``classes''. The most common are
``numeric'' (which you can do numerical calculations on), character (can
contain letters, numbers, symbols etc., but cannot run numerical
calculations), and logical (TRUE or FALSE). You can check the class of
a variable by using the ``class()'' function.  

\begin{lstlisting}
x <- 12345
class(x)
x + 1 # x is numeric, so addition is well defined

y <- "12345"
class(y)
y+1 # y is a character, so addition is not defined - produces an error
\end{lstlisting}

This threw up an error. Can you see why? The speech marks character `\verb:":'
is used to show that the class of y is ``character''. You can also use the
apostrophe '. There is a slight difference between these, but for now
this is not important. 

To see which objects are currently present in the R environment, use
the ``ls()'' command. To remove a particular object, use the ``rm()''
command. BE CAREFUL -- once you have removed an object, it is gone
forever! 

\begin{lstlisting}
x <- 5
ls()
rm(x)
ls()
rm(list=ls())  # Removes all objects in the current R session
\end{lstlisting}

You can also change the class of a variable by assigning to the
``class()'' function: 

\begin{lstlisting}
x <- "12345"
x+1
class(x)
class(x) <- "numeric"
class(x)
x+1
\end{lstlisting}

The other important data class is logical, which is simply a binary
TRUE or FALSE value. There are certain operators that are used to
compare two variables. The obvious ones are ``is less than'' ('\verb:<:'), ``is
greater than'' ('\verb:>:'), ``is equal to'' ('\verb:==:'). You can also combine these
to see ``is less than or equal to'' ('\verb:<=:') or ``is greater than or equal
to'' ('\verb:>=:'). If the statement is true, then it will return the output
``TRUE''. Otherwise it will return ``FALSE'': 

\begin{lstlisting}
x <- 2
y <- 3
x <= y  # Returns TRUE
x >= y  # Returns FALSE
\end{lstlisting}

You can also combine these logical tests to ask complex questions by
using the ``AND'' ('\verb:&&:') or the ``OR'' ('\verb:||:') operators. You can also
negate the output of a logical test by using the ``NOT'' ('\verb:!:')
operator. This lets you test for very specific events in your
data. Again, I recommend using parentheses to break up your tests to
ensure that the tests occur in the order which you expect: 

\begin{lstlisting}
x <- 3
y <- 7
z <- 6
(x <= 3 && y >= 8) && z == 6  # Returns FALSE
(x <= 3 && y >= 8) || z == 6  # Returns TRUE
\end{lstlisting}

One important set of functions are the log and exponential
functions. The exponential function is the function $e^{x}$, such that
$e^{x}$ is its own derivate ($\frac{d(e^{x})}{dx} = e^{x}$). The value
e is the constant 2.718281828..., and is a very important value in
mathematics (hence why it has it's own function). Logarithms are the
inverse of exponents.

\begin{lstlisting}
## Calculate log and exponential
log(8)      ## Natural logarithm (log base e)
log2(8)     ## Log base 2
exp(1)      ## e
exp(5)      ## e^5
log(exp(8)) ## Why does this work? 
exp(log(8)) ## Why does this work? 
2^(log2(8)) ## Why does this work? 
log2(2^8)   ## Why does this work?
\end{lstlisting}

### Vectors

Single values are all well and good, but R has a number of ways to
store multiple values in a single data structure. The simplest one of
these is as a ``vector'' -- simply a list of values of the same
class. You create a vector by using the ``c()'' function: 

\begin{lstlisting}
my_vector <- c(1,2,3,4,5)
my_vector
\end{lstlisting}

This is a very useful way of storing linked data together. You can
access the individual elements of the vector by using square brackets
(``['') to take a subset of the data. The elements in the vector are
numbered from 1 upwards, so to take the first and last values we do
the following: 

\begin{lstlisting}
my_vector   <- c(10,20,30,40,50)
first_value <-  my_vector[1] # Gets the first value, 10
last_value  <- my_vector[5] # Gets the fifth value, 50
no_value    <- my_vector[6] # No sixth value, so throws an error
first_value
last_value
no_value
\end{lstlisting}

As you can see, an error occurs if you try and take an element that
does not exist. The subset can be as long as you like: 

\begin{lstlisting}
my_vector  <- c(10,20,30,40,50)
sub_vector <- my_vector[1:4] # Takes the first 4 values in my_vector
sub_vector
\end{lstlisting}

Here, the ``:'' in the brackets simply means to take all of the numbers
from 1 through to 4, so this returns the first 4 elements of the
vector. For instance, this is a simple way to take the numbers from 1
to 20: 

\begin{lstlisting}
1:20
\end{lstlisting}

To drop elements from an array, you use the minus symbol:

\begin{lstlisting}
my_vector <- c(10,20,30,40,50)
my_vector[-1]
my_vector[-length(my_vector)]
my_vector[-c(1,3,5)]
\end{lstlisting}

Another way to generate a regular sequence in R is to use the ``seq()''
command. You supply the start number and the end number, and then
either supply the parameter ``by'' to define the regular interval
between values, or the parameter ``length'' to specify the total number
of values to return between the start and end value: 

\begin{lstlisting}
seq(from = 1, to = 20, by = 1) # Returns the same as 1:20
seq(from = 1, to = 20, by = 2) # Just the even numbers between 1 and 20
seq(from = 1, to = 20, length = 10) # Slightly different to above
\end{lstlisting}

You can also use the ``rep()'' function to give a vector of the
specified length containing repeated values: 

\begin{lstlisting}
rep(10, times = 5) # Returns vector containing five copies of the number 10
rep(c(1,2,3), each = 5) # Returns five 1s, then five 2s, then five 3s
\end{lstlisting}

One of the most powerful features of R is the fact that arithmetic can
be conducted on entire vectors rather than having to loop through all
values in the vector. For instance, if you sum two vectors (of equal
size), the result will be a vector where the ith entry is the sum of
the ith entries from the input vectors: 

\begin{lstlisting}
x <- c(2,3,2,4,5)
y <- c(4,1,1,2,3)
x + y
x * y
\end{lstlisting}

### Lists

Another data structure that is very useful is the ``list''. A list
contains a number of things in a similar way to the vector, but the
things that it contains can all be completely different classes. They
can even be vectors and other lists (a list of lists): 

\begin{lstlisting}
my_list <- list(12345, "12345", c(1,2,3,4,5))
my_list
\end{lstlisting}

To subset a list, the syntax is slightly different and you use 2
square brackets: 

\begin{lstlisting}
my_list <- list(12345, "12345", c(1,2,3,4,5))
first_value <- my_list[[1]]
last_value <- my_list[[3]]
first_value
last_value
\end{lstlisting}

If your list contains lists or vectors, you can subset these as well
by using multiple sets of square brackets: 

\begin{lstlisting}
my_list <- list(12345, "12345", c(1,2,3,4,5))
my_list[[3]][5]
\end{lstlisting}

Can you see the difference between subsetting using ``[['' and using
``[''?

\begin{lstlisting}
my_list <- list(12345, "12345", c(1,2,3,4,5))
my_list[[3]]  ## Returns a vector
my_list[3]    ## Returns a list
my_list[3][5] ## Not defined!
\end{lstlisting}

You can give names to the values in a vector or in a list by using the
``names()'' function to make it easier to follow what the values are: 

\begin{lstlisting}
my_vector <- c(1:5)
names(my_vector) <- c("length", "width", "height", "weight", "age")
\end{lstlisting}

You can use these names instead of the reference number to subset
lists and vectors: 

\begin{lstlisting}
my_vector <- c(1:5)
names(my_vector) <- c("length", "width", "height", "weight", "age")
age <- my_vector["age"]
age
\end{lstlisting}

The number of values in a vector or list can be found by using the
``length()'' function: 

\begin{lstlisting}
my_vector <- 1:5
length(my_vector)
\end{lstlisting}

We can also sort the data simply using the \texttt{sort()}
function. If we want to get the indeces of the sorted vector (for
instance to order a second vector based on the values in the first),
we can use the \texttt{order()} function:

\begin{lstlisting}
## Some values and their corresponding names
my_vals  <- c( 0.2,    1.7,    0.5,    3.4,    2.7  )
my_names <- c("val1", "val2", "val3", "val4", "val5")

## Sort the data
my_sorted <- sort(my_vals)  ## Returns the values in sorted order
my_order  <- order(my_vals) ## Returns the indeces of the sorted values

## What is the difference between the two?
my_sorted
my_order

## Get the sorted value names
sort(my_names)      ## This won't work as this will order names alphabetically
my_names[my_order]  ## This gives us the order based on the values themselves
\end{lstlisting}

By default the sort functions sort from lowest to highest. You can
sort in decreasing by order by using the \texttt{decreasing}
parameter:

\begin{lstlisting}
sort(my_vals, decreasing = TRUE)
\end{lstlisting}


### Matrices

Another data format is a ``matrix'' (also known as an ``array''). This is
simply a table of values, and can be thought of as a multidimensional
vector. To access specific values in the matrix, you again use the
square bracket accessor function, but this time must specify both the
row (first value) and column (second value): 

\begin{lstlisting}
my_matrix <- matrix(1:20, nrow = 5, ncol = 4)
my_matrix
my_matrix[3,4] <- 99999
my_matrix
\end{lstlisting}

By default, the values are added to the matrix in a column-wise
fashion (from top to bottom for column 1, then the same for column 2,
etc.). To fill the matrix in a row-wise fashion, use the
\texttt{byrow} parameter:

\begin{lstlisting}
my_matrix <- matrix(1:20, nrow = 5, ncol = 4, byrow = TRUE)
\end{lstlisting}

You can also use the square bracket accessor function to extract
subsets of the matrix: 

\begin{lstlisting}
my_matrix <- matrix(1:20, nrow = 5, ncol = 4)
my_matrix
sub_matrix <- my_matrix[1:2, 3:4]
sub_matrix
\end{lstlisting}

The ``cbind()'' (column bind) and ``rbind()'' (row bind) functions can
also be used to concatenate vectors together by row or by column to
give a matrix: 

\begin{lstlisting}
my_matrix_col <- cbind(c(1,2,3), c(4,5,6), c(7,8,9)) 
my_matrix_col
my_matrix_row <- rbind(c(1,2,3), c(4,5,6), c(7,8,9)) 
my_matrix_row
\end{lstlisting}

You can change the names of both the rows and the columns by using the
``rownames()'' and ``colnames()'' functions: 

\begin{lstlisting}
my_matrix <- matrix(1:20, nrow = 5, ncol = 4)
rownames(my_matrix) <- c("row1", "row2", "row3", "row4", "row5")
colnames(my_matrix) <- c("col1", "col2", "col3", "col4")
my_matrix
\end{lstlisting}

The dimensions of the matrix can be found by using the ``dim()''
function, which gives the number of rows (first value) and the number
of columns (second value) of the matrix. You can access the number of
rows or columns directly by using the ``nrows()'' or ``ncols()'' functions
respectively: 

\begin{lstlisting}
my_matrix <- matrix(1:20, nrow = 5, ncol = 4)
dim(my_matrix)
nrows(my_matrix)
ncols(my_matrix)
\end{lstlisting}

### Functions

R also uses functions (also known as methods) which simply take in one
or more values, do something to them, and return the results of
whatever this something is. A simple example is the ``sum()'' function,
which takes in two or more values in the form of a vector, and returns
the sum of all of the values: 

\begin{lstlisting}
my_vector <- c(1:5)
my_sum <- sum(my_vector)
my_sum
\end{lstlisting}

In this example, the ``sum()'' function takes only one variable (in this
case a numeric vector). Sometimes functions take more than one
variable (also known as ``arguments''). These are named values that
must be specified for the function to run. For example, the ``cor()''
function returns the correlation between two vectors. This requires
several variables to be supplied - two vectors of equal length - and
you can also supply a number of additional arguments to control how
the function works, including the ``method'' argument, which lets you
specify which method to use to calculate the correlation: 

\begin{lstlisting}
sample1 <- c(0.9, 1.2, 8.9, -0.3, 6.4)
sample2 <- c(0.6, 1.3, 9.0, -0.5, 6.2)
pearson_cor <- cor(sample1, sample2, method = "pearson")
spearman_cor <- cor(sample1, sample2, method = "spearman")
pearson_cor
spearman_cor
\end{lstlisting}

Note that the Pearson correlation is the default, so you could get
this by simply typing: 

\begin{lstlisting}
pearson_cor <- cor(sample1, sample2)
\end{lstlisting}

Note that we named the third argument (``method''), but not the first
two. If you do not name arguments, they will be taken and assigned to
the arguments in the order in which they are input. The first two
arguments required by the function are ``x'' and ``y'' - the two vectors
to compare. So there is no problem with not naming these (although you
could if you wanted to). However, there are more arguments for
``cor()'' for which we are happy to use the default value before we get
to ``method'', so we need to name it to make sure that ``pearson'' is not
assigned to the wrong variable in the function. It is always safer to
name the arguments if you are unsure of the order. 

If you want to find out what a function does, there is a lot of
documentation available in R. Depending on who has written this, it
can be incredibly helpful or incredibly useless... To see the
documentation for a specific function, use the ``help()'' function. If
you want to try and find a function, you can search using a keyword by
using the ``help.search()'' function: 

\begin{lstlisting}
help(cor)
?cor # Alternative for help()
help.search("correlation")
??correlation # Alternative for help.search()
\end{lstlisting}

### Printing

``print()'' can be used to print whatever is stored in the variable the
function is called on. Print is what is known as an ``overloaded''
function, which means that there are many functions named ``print()'',
each written to deal with a variable of a different class, and the
correct one is used based on the variable that you supply. So calling
``print()'' on a numeric variable will print the value stored in the
variable. Calling it on a vector prints all of the values stored in
the vector. Calling it on a list will print the contents of the list
split into an easily identifiable way. There are also many more
classes in R for which print is defined, but there are too many to
describe here: 

\begin{lstlisting}
x <- 1
print (x)
y <- 1:5
print (y)
z <- list(val1 = 1:5, val2 = 6:10)
print (z)
\end{lstlisting}

If you notice, using ``print()'' is the default when you just call the
variable itself: 

\begin{lstlisting}
z <- list(val1 = 1:5, val2 = 6:10)
print (z)
z
\end{lstlisting}

``cat()'' is similar to print in that the results of calling it are that
text is printed to the console. The main use for ``cat()'' is to
conCATenate two or more variables together and instantly print them to
the console. The additional argument ``sep'' gives the character to use
to separate the different variables: 

\begin{lstlisting}
cat("hello", "world", sep = " ")
x <- 1:5
y <- "bottles of beer"
cat(x, y, sep = "\t")
\end{lstlisting}

The ``\verb:\t:'' is a special printing character that you can use with the
``cat()'' function that prints a tab character. Another similar special
character that you may need to use is ``\verb:\n:'' which prints a new line.  

Another similar function is the ``paste()'' function, which also
concatenates multiple values together. The differences between this
and ``cat()'' are that the results of ``paste()'' can be saved to a
different variable which requires a call to ``print()'' to see the
results, and ``paste()'' can be used to concatenate individual elements
of a vector by using the additional ``collapse'' argument: 

\begin{lstlisting}
print(paste("hello", "world", sep = "\t"))
print(paste("sample", 1:5, sep="_")) # Returns a vector of values
print(paste("sample", 1:5, sep="_", collapse="\n")) # Prints values separated by new lines
\end{lstlisting}

Do you notice the difference between ``print()'' and ``cat()''? While
``print()'' prints the ``\verb:\t:'' character as is, ``cat()'' prints the actual
tab space. This is a process known as ``interpolation''.  


## Installing Packages

The main R package contains a large number of commonly used
functions. There are also additional functions available in other
``packages'' that you can get hold of from the Comprehensive R Archive
Network, or CRAN, which you can access from the R homepage. To load in
a package, making the package functions available to be used in your
current R session, use the ``library'' command: 

\begin{lstlisting}
?xtable
library("xtable")
?xtable
\end{lstlisting}

The function ``xtable()'' is not available in the R environment until
you have loaded the package ``gtools''. Only the most commonly used
functions are made available in the R environment by default (for
example the package ``stats'' is loaded by default, which contains all
commonly used statistical fuctions). There are also a number of
commonly used packages that are part of the R installation, but which
are not automatically loaded when you start a new R session. There are
also thousands of additional packages available, some written by
users, which can perform most of the things that you would ever want
to do. Chances are, if you want to do something it's available from
somewhere. Don't re-invent the wheel if you can help it. To install a
package, simply use the ``install.packages()'' function: 

\begin{lstlisting}
install.packages("car")
\end{lstlisting}

Since R is so useful for analysing biological data, the ``bioconductor''
project was set up to bring together packages used for the analysis of
high-throughput data (it started with microarrays, but now there are
packages available for analysis of sequencing data). Bioconductor
packages can be downloaded from \href{http://www.bioconductor.org/}{http://www.bioconductor.org/}. However,
there is also a simple way to install bioconductor packages directly
from within R: 

\begin{lstlisting}
source("http://bioconductor.org/biocLite.R") # Load the biocLite() script
biocLite()  # Installs the basic packages required to use bioconductor
biocLite("DESeq") # Installs a specific bioconductor package
\end{lstlisting}


## Data Frames

Data frames are the most powerful data types in R. They look similar
to matrices, but the data structure is actually more similar to a list
of vectors (all of the same length). The simplest way to think of them
is as being similar to spreadsheets in Excel.  

You can create data frames either in a similar way to how you create a
list, or also by converting a matrix object: 

\begin{lstlisting}
my_df <- data.frame(val1 = c(1:3), val2 = c(4:6), val3 = c(7:9), val4 = c(10:12))
my_df
my_df <- as.data.frame(matrix(1:12, nrow = 3, ncol = 4))
my_df
\end{lstlisting}

Notice how, in the second data frame, no data names are specified so R
sets the defaults as ``V1'', ``V2'', ``V3'', etc. Whilst data frames do have
rownames, it is the column names that are the most important. As with
lists, these can be changed by using the ``names()'' command: 

\begin{lstlisting}
my_df <- as.data.frame(matrix(1:12, nrow = 3, ncol = 4))
names(my_df) <- c("val1", "val2", "val3", "val4")
my_df
\end{lstlisting}

You access the elements of a data frame either in the same way as for
a matrix, or you can access the individual columns in the same way as
for lists. You can also access the individual columns by using the
special ``\$'' operator which is specifically used for data frames: 

\begin{lstlisting}
my_df <- as.data.frame(matrix(1:12, nrow = 3, ncol = 4))
names(my_df) <- c("val1", "val2", "val3", "val4")
my_df
sub_df <- my_df[2:5, 1:2]
sub_df
val1 <- my_df[[1]]
val1
val2 <- my_df[["val2"]]
val2
val3 <- my_df$val3
val3
\end{lstlisting}

The beauty of data frames is that the data frame columns can be dealt
with as if they were individual variables. For this reason, the column
names must be suitable variable names (i.e. alphanumeric and not
starting with a number) and must be unique. If you attach a data
frame, you can access the columns as if they were variables: 

\begin{lstlisting}
my_df <- data.frame(val1 = c(1:3), 
                    val2 = c(4:6), 
                    val3 = c(7:9), 
                    val4 = c(10:12))
attach(my_df)
my_df
my_df$val1 <- val1 + 1000
my_df
detach(my_df)
\end{lstlisting}

Notice that to make changes to the data frame itself, we need to use
the ``\$'' accessor function (or double square brackets), otherwise a
new variable ``val1'' will be created.  
Data frames should be set up in such a way that every row represents
an independent observation, and the columns represent the independent
variables that you may be interested in. For instance, if you have
taken a measurement of say the weight of each sample in triplicate,
you would not represent the data like this: 

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{llll}
      SampleName & Weight1 & Weight2 & Weight3 \\
      \hline
      Sample1	   & 67.1    & 67.3    & 66.8    \\
      Sample2	   & 80.3    & 79.8    & 79.5    \\
    \end{tabular}
  \end{center}
\end{table}

But instead you would ensure that the two independent variables
(weight and replicate number) were in their own columns: 

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{lll}
      SampleName & Replicate & Weight \\
      \hline
      Sample1    & 1         & 67.1   \\
      Sample1    & 2         & 67.3   \\
      Sample1    & 3         & 66.8   \\
      Sample2    & 1         & 80.3   \\
      Sample2    & 2         & 79.8   \\
      Sample2    & 3         & 79.5   \\
    \end{tabular}
  \end{center}
\end{table}
\FloatBarrier

Now all of the weights are in a single column that can be analysed.

Subsetting a data frame is also very powerful. The subset command
allows you to look for the rows of a data frame that fit certain
criteria. For instance, to pull out the genes that show more than
2-fold expression and a p-value less than 0.05, you would do the
following: 

\begin{lstlisting}
gene_exp <- data.frame(geneName   = paste("gene", 1:10, sep = ""),
                       foldChange = rnorm(10, mean = 2, sd = 1), 
                       pVal       = rnorm(10, mean = 0.05, sd = 0.05))
signif_genes <- subset(gene_exp, foldChange > 2 & pVal <= 0.05)
signif_genes
\end{lstlisting}

Notice here that we use a single ``\verb:&:'' rather than the double ``\verb:&&:'' that
we used earlier. This is because we are doing a vector-based logical
test (that is performing the test on each element of the vector to get
a vector of logical values at the end). It is very easy to forget this
and accidentally use the ``\verb:&&:'', which will not give you what you want: 

\begin{lstlisting}
real_signif_genes <- subset(gene_exp, foldChange > 2 & pVal <= 0.05)
real_signif_genes
fake_signif_genes <- subset(gene_exp, foldChange > 2 && pVal <= 0.05)
fake_signif_genes
\end{lstlisting}

Another form of data that comes in very handy, particularly with data
frames, is the ``factor''. Factors are a way of dealing with categorical
data, and simply encode the possible levels with values 0, 1, 2,
etc. (which is useful in more complex modelling procedures): 

\begin{lstlisting}
my_vector <- c("apples", "pears", "apples", "oranges", "pears")
my_vector
my_factor <- as.factor(my_vector)
my_factor
levels(my_factor)
\end{lstlisting}


## Reading and Writing Data

Reading and writing data in R is quite simple, and is most easily done
by using pure text files. Functions exist for reading other formats as
well, but for now we will concentrate on text.  

Unless you give the complete path for a file, R will look in it's
current working directory for any files that you want to load in. By
default, R will use your system's home directory (usually
\verb:/Users/[UserName]/:), but you can set this by using the
\texttt{setwd()} function. You can check that the correct working
directory is set by using the \texttt{getwd()} function:

\begin{lstlisting}
setwd("/Users/samrobson/Documents/Courses/R_and_bioinformatics_basics_course/examples")
getwd()
\end{lstlisting}

If you have a list of data in a file (e.g. a list of gene names
separated by new lines), then the simplest method to use is
``scan()''. You must tell ``scan()'' where to find the data file (either
the full path, or a relative path from the current working directory),
as well as the format that the data should be read in as (generally
either ``character'' or ``numeric''): 

\begin{lstlisting}
my_file   <- "gene_list.txt"
gene_list <- scan(my_file, what = "character", sep = "\n")
gene_list
\end{lstlisting}

For tables (for instance tab-delimited files saved from Excel), the
easiest way is to use the ``read.table()'' function. This works by using
``scan()'' to read in each line from the table, then splitting the line
by the specified delimiter. It is easier to read such files when there
are no empty cells, so try to fill empty data with a ``data missing''
character, such as ``NA'' (the default). There are lots of additional
arguments to the ``read.table()'' function. ``header'' is a boolean value
that says whether or not the first row should be used to name the
columns of the data frame, sep gives the delimiter between column
entries (e.g. ``$\backslash$t'' for tab-delimited files, or ``,'' for comma-separated
files). By default, ``read.table()'' converts character columns into
factors, which can be avoided by setting the ``stringsAsFactors''
argument to FALSE: 

\begin{lstlisting}
my_file   <- "sample_annotation.txt" 
sample_ann <- read.table(my_file, header = TRUE, sep = "\t", 
                         stringsAsFactors = FALSE)
sample_ann
sample_ann <- read.table(my_file, header = FALSE, sep = "\t", 
                         stringsAsFactors = FALSE, skip = 3, nrow = 2)
sample_ann
\end{lstlisting}


## Control Sequences

One of the most useful things to be able to do with computers is to
repeat the same command multiple times without having to do it by hand
each time. For this, control sequences can be used to give you close
control over the progress of your program. 

### IF ELSE

The first control sequence to look at is the ``if else'' command, which
acts as a switch to run one of a selection of possible commands given
a switch that you specify. For instance, you may want to do something
different depending on whether a value is odd or even: 

\begin{lstlisting}
my_val <- 3
if (my_val%%2 == 0) {  # If it is even (exactly divisible by 2)
  cat ("Value is even\n")
} else { # Otherwise it must be odd
  cat ("Value is odd\n")
}
\end{lstlisting}

Here, the expression in the parentheses following ``if'' is evaluated,
and if it evaluates to TRUE then the block of code contained within
the following curly braces is evaluated. Otherwise, the block of code
following the ``else'' statement is evaluated. You can add additional
tests by using the ``else if'' statement: 

\begin{lstlisting}
my_val <- 27
if (my_val%%2 == 0) {
  cat("Value is divisible by 2\n") 
} else if (my_val%%3 == 0) {
  cat("Value is divisible by 3\n")
} else if (my_val%%4 == 0) {
  ...
} else if (my_val%%n == 0) {
  cat("Value is divisible by n\n")
} else {
  cat("Value is not divisible by 1:n\n")
}
\end{lstlisting}

Each switch is followed by a block of code surrounded by curly braces,
and the conditional statements are evaluated until one evaluates to
TRUE, at which point R avaluates this code bloack then exits. If none
of them evaluate to TRUE, then the default code block following ``else''
is evaluated. If no ``else'' block is present, then the default is to do
nothing. These blocks can be as complicated as you like, and you can
have ``if else'' statements within the blocks to create a hierarchical
structure. 

### FOR

Another control structure is the ``for loop'', which will conduct the
code in the block multiple times for a variety of values that you
specify at the start. For instance, here is a simple countdown script: 

\begin{lstlisting}
for (i in 10:1) {
  cat(i, "...\n", sep = "")
  if (i == 1) {
    cat("Blastoff!\n")
  }
}
\end{lstlisting}

So the index ``i'' is taken from the set of numbers (10, 9, ..., 1),
starting at the first value 10, and each time prints out the number
followed by a newline. Then an ``if'' statement checks to see if we have
reached the final number, at which point it is time for blast off! At
this point, it returns to the start of the block, updates the number
to the second value 9, and repeats. It does this until there are no
more values to use. 

As a small aside, this is slightly inefficient. Evaluation of the ``if''
statement is conducted every single time the loop is traversed (10
times in this example). It will only ever be true at the end of the
loop, so we could always take this out of the loop and evaluate the
final printout after the loop is finished and save ourselves 10
calculations. Whilst the difference here is negligible, thinking of
things like this may save you time in the future: 

\begin{lstlisting}
for (i in 10:1) {
  cat(i, "...\n", sep = "")
}
cat("Blastoff!\n")
\end{lstlisting}

### WHILE

The final main control structure is the ``while loop''. This is similar
to the ``for loop'', and will continue to evaluate the code chunk as
long as the specified expression evaluates to TRUE: 

\begin{lstlisting}
i <- 10
while (i > 0) {
  cat(i, "...\n", sep = "")
  i <- i - 1
} 
cat("Blastoff!\n")
\end{lstlisting}

This does exactly the same as the ``for loop'' above. In general, either
can be used for a given purpose, but there are times when one would be
more ``elegant'' than the other. For instance, here the for loop is
better as you do not need to manually subtract 1 from the index each
time. However, if you did not know how many iterations were required
before finding what you are looking for (for instance searching
through a number of files), a ``while loop'' may be more suitable. 

HOWEVER: Be aware that it is possible to get caught up in an ``infinite
loop'' with ``while loops''. This happens if the conditional statement
never evaluates to FALSE. If this happens, press either ESCAPE or
press the CONROL key and
the letter c (\verb:CTRL+c:) to quit out of the current function. For
instance, if we forget to decrement the index, i will always be 10 and
will therefore never be less than 0: 

\begin{lstlisting}
i <- 10
while (i > 0) {
  cat(i, "...\n", sep = "")
} 
cat("Blastoff!\n")
\end{lstlisting}

### Loop Control

You can leave control loops early by using flow control
constructs. ``next'' skips out of the current loop and moves onto the
next in the sequence:  

\begin{lstlisting}
for (i in 1:10) {
  if (i == 5) {
    next
  }
  cat (i, "\n", sep = "")
}
cat("Finished loop\n")
\end{lstlisting}

``break'' will leave the loop entirely, and will return to the function
after the last curly brace in the code chunk: 

\begin{lstlisting}
for (i in 1:10) {
  if (i == 5) {
    break
  }
  cat (i, "\n", sep = "")
}
cat("Finished loop\n")
\end{lstlisting}


## Writing Functions in R

There are many functions available in R, and chances are if you want
to do something somebody has already written the function to do it. It
is best to not re-invent the wheel if possible, but very often you
will want to create your own functions to save replicating code. A
function takes in one or more variables, does something with them, and
returns something. For instance, calculating the mean of a number of
values is simply a case of adding them together and dividing by the
number of values. Let's write a function to do this and check that it
matches the ``mean()'' function in R: 

\begin{lstlisting}
my_mean <- function (x) {  # Here, x is a numeric vector
  nvals <- length(x)
  valsum <- sum(x)
  return (valsum/nvals)
}
my_vals <- c(3,5,6,3,4,3,4,7)
my_mean(my_vals)
mean(my_vals)
\end{lstlisting}

So, as with the loops earlier, the function is contained within a
block of curly braces. A numeric vector is given to the function, the
mean is calculated, and this value is returned to the user using the
``return()'' function. This value can be captured into a variable of
your choosing in the same way as with any function.  

You can also add further arguments to the function call. If you want
a argument to have a default value, specify it in the function
declaration. Any arguments that do not have a default value must be
specified when calling the function, or an error will be thrown: 

\begin{lstlisting}
## No default argument
foo <- function(x, arg) {
  return(paste(x, arg, sep = " "))
}
foo ("Hello") # Throws an error since "arg" is not set
foo ("Hello", arg = "World!") # Prints "Hello World!"

## Add a default argument
foo <- function(x, arg = "World!") {
  return(paste(x, arg, sep = " "))
}
foo ("Hello") # Prints "Hello World!"
\end{lstlisting}

This is a good point to mention an idea known as ``scope''. After
running this function, have a look at the value ``valsum'' calculated
within the function: 

\begin{lstlisting}
my_mean <- function (x) {  # Here, x is a numeric vector
  nvals <- length(x)
  valsum <- sum(x)
  return (valsum/nvals)
}
my_vals <- c(3,5,6,3,4,3,4,7)
my_mean(my_vals)
print(valsum)   ## Error: Can't find valsum. Where is it then?!
\end{lstlisting}

What went wrong? The error message says that R cannot find the object
``valsum''. So where is it? The ``scope'' of an object is the environment
where it can be found. Up until now, we have been using what are known
as ``global variables''. That is we have created all of our objects
within the ``global environment'', which is the top level where R
searches for objects. These objects are available at all
times. However, when we call a function, a new environment, or
``scope'', is created, and all variables created within the function
become ``local variables'' that can only be accessed from within the
function itself. As soon as we leave the function, these local
variables are deleted. If you think about it, this makes
sense. Otherwise, every time we called a function, our memory would
fill up with objects which we had no idea what they were. Also, how
many functions do you think create an object called ``x''? Pretty much
all of them (it's generally the default argument, as in my
example). If we created an object ``x'', then ran a couple of functions,
and then went to use ``x'' again, chances are it would no longer be what
we thought it was.  

So, the function itself is completely self-contained. A copy of the
input variable is created in ``x'', something is done to this object
(possibly creating additional objects along the way), something is
returned, and then all of these objects in the scope of the function
are removed, and we move back into the global environment.  

Functions are incredibly useful when we want to repeat the same set of
actions on multiple sets of data. The ``apply'' set of functions are
very useful for running a single function multiple times on input
data.  

``apply()'' works on a matrix or data frame, and applies the function
named by the argument ``FUN'' across either the rows or the columns of
the table, as specified with the ``MAR'' (margin) argument (\verb:MAR=1: for
rows, \verb:MAR=2: for columns). For instance, suppose that you had a matrix
of expression values from a microarray, where each row was a different
gene, and each column is the signal from a different probe on the
array. We may want to calculate the mean value across these probes for
each gene: 

\begin{lstlisting}
probe_file  <- "probe_values.txt"
probe_dat   <- read.table(probe_file, header = TRUE, sep = "\t")
probe_means <- apply(probe_dat[, -1], MAR = 1, FUN = mean)
probe_means 
\end{lstlisting}

Additionally, apply can be used to apply a function to all values by
using \verb:MAR=c(1,2): to run across rows and columns: 

\begin{lstlisting}
probe_file    <- "probe_values.txt"
probe_dat     <- read.table(probe_file, header = TRUE, sep = "\t")
probe_dat_log <- apply(probe_dat[, -1], MAR = c(1,2), FUN = exp)
probe_dat_log
\end{lstlisting}

The same results can be generated by using a ``for loop'' to loop over
all entries, but this is much slower.  

``lapply()'' (``list apply'') is similar but runs over a list of values,
and returns the output as a list of values. In this example, the mean
is calculated for a number of vectors, but these vectors can be
different sizes (unlike for a matrix or data frame): 

\begin{lstlisting}
my_list <- list(val1 = c(2,4,2,3,4,3,4), val2 = c(1,2), val3 = c(10,2,5,9))
lapply(my_list, FUN = mean)
\end{lstlisting}

However, since the output is a list, the output could also be a list
of vectors: 

\begin{lstlisting}
my_list <- list(val1 = c(2,4,2,3,4,3,4), val2 = c(1,2), val3 = c(10,2,5,9))
lapply(my_list, FUN = sort)
\end{lstlisting}

``sapply()'' (``simple apply'') is similar to ``lapply()'', but returns the
results as a vector rather than a list. This is a better method to use
when returning a single value for each list entry: 

\begin{lstlisting}
my_list <- list(val1 = c(2,4,2,3,4,3,4), val2 = c(1,2), val3 = c(10,2,5,9))
sapply(my_list, FUN = mean)
\end{lstlisting}



## Some Simple Statistics

R is mainly designed for easy computation of statistics and there
in-built functions and additional modules that allow you to calculate
pretty much anything that you might want to calculate. Most simple
statistics can be easily calculated using in-built functions:

\begin{lstlisting}
## Create random vectors of 100 values sampled from a normal distribution with mean 0 and standard deviation 1
x1 <- sort(rnorm(100, mean = 0, sd = 1))
x2 <- sort(rnorm(100, mean = 0, sd = 1))

## Calculate some simple statistics
min(x1)                              ## Minimum value
max(x1)                              ## Maximum value
mean(x1)                             ## Mean value (standard average) - should be about 0
median(x1)                           ## Median value (middle value/2nd quartile)
quantile(x1, probs = 0.25)           ## 1st quartile
quantile(x1, probs = 0.75)           ## 3rd quartile
quantile(x1, probs = seq(0, 1, 0.1)) ## Every 10th percentile

## Calculates all of the following in one go
summary(x1)

## Calculate the standard deviation (should be about 1)
sd(x1)

## Calculate variance and covariance
var(x1)      ## Note that this is sd(x1)^2
var(x2)
cov(x1, x2)

## Calculate the correlation between the two values
cor(x1, x2)                      ## Calculates Pearson correlation by default
cov(x1, x2)/(sd(x1) * sd(x2))    ## Shows the link between correlation and variance
cor(x1, x2, method = "spearman") ## Use Spearman correlation (same as above but uses ranks)

## Calculate the line of best fit between the two vectors (linear regression)
my_lin_mod <- lm(x2 ~ x1)   ## Literally means x2 is modelled by x1 
summary(my_lin_mod)

## Perform a t-test to see if there is a significant difference between the means
t.test(x1, x2) ## 2-sided t-test by default

## Since both are drawn from the same distribution, the test shows 
## there is no evidence that there is a difference between the mean.
## Try again with a different data set
x3 <- rnorm(100, mean = 10, sd = 1)
t.test(x1, x3)                          ## 2-sided t-test by default
t.test(x1, x3, alternative = "less")    ## Tests if mean(x1) < mean(x3)
t.test(x1, x3, alternative = "greater") ## Tests if mean(x1) > mean(x3)

## Create an example logical data frame
x <- data.frame(GeneName      = c("gene1", "gene2", "gene3", "gene4", "gene5"),
                IsUpregulated = c( TRUE,    TRUE,    FALSE,   FALSE,   FALSE ),
                IsEven        = c( FALSE,   TRUE,    FALSE,   TRUE,    FALSE )
                )

## Count the number of occurences of each discrete value
table(x[["IsUpregulated"]]) 
table(x[["IsUpregulated"]], x[["IsEven"]]) ## Generates a 2-dimensional table of counts across both vectors

## Calculate significance of the number of upregulated genes that are even numbered
chisq.test( table(x[["IsUpregulated"]], x[["IsEven"]]))  ## Warning as too few values
fisher.test(table(x[["IsUpregulated"]], x[["IsEven"]]))
\end{lstlisting}



## Plotting With R

One of the most useful functions of R is the ability to plot
publication-quality figures simply and easily. The vast number of
tools available to users for plotting figures is beyond the scope of
this tutorial, but I will mention a few of the most commonly used
plotting functions to allow you to have a quick look at your data.

### Scatterplots

Scatterplots are probably the simplest plot that we can look at. Here
we take two sets of values and plot one against the other to see how
they correlate. This means that the two data sets are paired, such
that the first element of each data set represents one event, the
second represents another, and so on. For instance, for every student
in a class, we may have scores from tests taken at the start and at
the end of the year, and we want to compare them against one another
to see how they compare. Here is how to plot a simple scatterplot: 

\begin{lstlisting}
## Create some random data (both drawn from the same standard normal distribution)
x1 <- rnorm(100, mean = 0,  sd = 1)
x2 <- rnorm(100, mean = 0,  sd = 1)

## Plot a simple scatterplot to see the level of correlation
plot(x = x1, y = x2)

## Same plot, but with a few changes to make it look nicer
plot(x = x1, y = x2,
     pch  = 19,                  ## Plot each point as a filled circle
     col  = "red",               ## Colour each point red
     xlab = "This is x1",        ## Add a label to the x-axis
     ylab = "This is x2",        ## Add a label to the y axis
     main = "This is x2 vs. x1", ## Add a main title to the plot
     cex.main = 1.4,             ## Change the size of the title
     cex.lab  = 1.2,             ## Change the size of the axis labels
     cex.axis = 1.1              ## Change the size of the axis values
     )
\end{lstlisting}

There are lots of additional plotting arguments that can be set in
the \texttt{plot()} command. These are just a few. These arguments
will typically work for any plotting function that you may want to use.

\texttt{plot()} is
the standard plotting function, and works differently depending on the
type of data on which it is called. Most of the following plots use
this function in some way, even though it may not be obvious.

Here we have coloured all of our points a single colour by using the
\verb:col = "red": argument. However, we can assign colours to each
point separately by supplying a vector of colours that is the same
length as x and y. This means that we can set colours based on the
data themselves:

\begin{lstlisting}
my_cols <- rep("black", length(x1))
my_cols[x1 > 1 & x2 > 1]  <- "red"
my_cols[x1 > 1 & x2 < -1] <- "green"
my_cols[x1 < 0 & x2 > 0]  <- "blue"
plot(x = x1, y = x2, col = my_cols, pch = 19)
\end{lstlisting}

Since this plot is useful for observing the level of correlation
between two data sets, it may be useful to add a couple of lines in to
the plot to help us determine if there is a trend indicating that x1
is well correlated with x2. First of all we will add lines in through
the origin, and then we will add in a dotted line along the $x = y$ line
(since, if the two datasets were exactly correlated, the points would lie on
this line). To do this, we use the \texttt{abline()} function. This
plots a straight line in one of three ways. We can either specify a
horizontal line by specifying the \texttt{h} argument, or we can
specify a vertical line by using the \texttt{v} argument, or we can
specify a straight line in the format $y = a + bx$ (where a is the
intercept term and b is the gradient term):

\begin{lstlisting}
plot(x = x1, y = x2, ylim = c(-3,3), xlim = c(-3,3))
abline(h = 0)
abline(v = 0)
abline(a = 0, b = 1, lty = 2) ## lty gives the line type - in this case dotted
\end{lstlisting}

Notice that \texttt{abline()} does not create a new plot, but instead
adds to the plot that we already have. This is because it does not
call the \texttt{plot.new()} function, which would otherwise create a new
plotting region.

We may be particularly interested in how the line of best fit looks as
compared to the $x = y$, as this will show us if there is a general
trend in the data or not. To do this we can use a linear model to
predict 'a' and 'b' from the data:

\begin{lstlisting}
## Plot the line of best fit through the data
my_lin_model <- lm(x2 ~ x1) ## Note it is x2 ~ x1, not x1 ~ x2 since x2 is the y value
abline(my_lin_model, lty = 2, col = "red")

## If you want to explicitly pull out a and b, use the coef() function to get the coefficients
a <- coef(my_lin_model)[1]  ## Get the intercept from the coefficients of the model
b <- coef(my_lin_model)[2]  ## Get the gradient from the coefficients of the model
\end{lstlisting}

### Histograms

Now let's look at the distribution of the data. A histogram is
useful for this. Here we count up the number of values that fall into
discrete bins. The size of the bins (or the number of bins) can be
specified by using the 'breaks' argument     

\begin{lstlisting}
x <- rnorm(1000)
hist(x)               ## Shows a nice bell shape curve about mean 0
hist(x, breaks = 200) ## More fine-grained
\end{lstlisting}

### Quantile-Quantile Plots

Quantile-quantile plots are a particular type of scatterplot that are
used to see if two data sets are drawn from the same distribution. To
do this, it plots the quantiles of each data set against each
other. That is it plots the $0^{th}$ percentile of data set A (the minimum
value) against the $0^{th}$ percentile of data set B, the $50^{th}$
percentiles (the medians) against each other, the $100^{th}$ percentiles
(the maximum values) against each other, etc. Simply, it sorts both
data sets, and makes them both the same length by estimating any
missing values, then plots a scatterplot of the sorted data. If the
two data sets are drawn from the same distribution, this plot should
follow the $x = y$ identity line at all but the most extreme points:

\begin{lstlisting}
## Two data sets drawn from the same normal distribution
x1 <- rnorm(100,  mean = 0, sd = 1)
x2 <- rnorm(1000, mean = 0, sd = 1)
qqplot(x1, x2)
abline(a = 0, b = 1, lty = 2)

## Two data sets drawn from different normal distributions
x1 <- rnorm(100,  mean = 0, sd = 1)
x2 <- rnorm(1000, mean = 1, sd = 3)
qqplot(x1, x2)
abline(a = 0, b = 1, lty = 2)
\end{lstlisting}

\subsubsection{Line Plots}

Scatterplots are useful for generating correlation plots for pairs of
data. Another form of data is a set of values along a continuum, for
instance we may have the read count along the length of the
genome. For this, a scatterplot may not be the most sensible way of
viewing these data. Instead, a line plot may be a more fitting way of
viewing the data. To do this we simply specify the \texttt{type}
argument to be ``line'' (or simply ``l'').

One thing to be careful of with data such as this is
that you must make sure that the data are ordered from left to right
(or right to left) on the x axis so that connecting the points makes
sense on the continuum:

\begin{lstlisting}
x = c(2,4,5,3,1,7,9,8,6,10)
y = c(4,2,5,4,10,6,6,5,6,9)
plot(x = x, y = y, type = 'l')                     ## Not terribly useful!
plot(x = x[order(x)], y = y[order(x)], type = 'l') ## Much better
\end{lstlisting}

You can also plot both points and lines by setting the \texttt{type}
argument to ``both'' (or ``b''):

\begin{lstlisting}
plot(x = x[order(x)], y = y[order(x)], type = 'b')
\end{lstlisting}

\subsubsection{Density Plots}

We can use a line plot like this to plot the density of the data,
which gives us a similar plot to the histogram. The benefit of this
type of plot over a histogram is that you can overlay the distribution
of multiple data sets. The \texttt{density()} function is a kernal
density estimator function that basically calculates the density of
the data within each bin such that the total area under the resulting
curve is 1. This makes these plots useful for comparing data sets of
different sizes as they are essentially normalised:

\begin{lstlisting}
## Create 2 random normal distributions about 5 and 10 respectively
x1 <- rnorm(100,  mean = 5, sd = 1)
x2 <- rnorm(1000, mean = 10, sd = 1)

## Calculate the density of each
x1dens <- density(x1)
x2dens <- density(x2)

## Set up a plotting region explicitly
plot.new()                                                     ## Start a new plotting region
plot.window(xlim = c(0,15), ylim = c(0,0.5))                   ## Define the plot window range
title(xlab = "Value", ylab = "Density", main = "Density Plot") ## Label the figure
axis(1)                                                        ## Add axis on x-axis
axis(2)                                                        ## Add axis on y-axis

## Add the data (notice that these do not call plot.new() so will add onto the current figure
lines(x1dens, col = "red")
lines(x2dens, col = "blue")
\end{lstlisting}

We can add a legend to this plot to make it clear which line
represents which sample. Again, this does not call \texttt{plot.new()}
so will appear on top of the current plot:

\begin{lstlisting}
legend("topleft", legend = c("Mean = 5", "Mean = 10"), col = c("red", "blue"), lty = 1)
\end{lstlisting}

\subsubsection{Boxplots}

Another way to compare the distribution of two (or more) data sets is
by using a boxplot:

\begin{lstlisting}
boxplot(x1, x2, names = c("Mean = 5", "Mean = 10"), ylab = "Value")
\end{lstlisting}

Boxplot can also take the data in the form of a data frame, which is
useful for instance if you want to compare the distribution of
expression values over all genes for a number of different
samples. This will automatically label the boxes with the column names
from the data frame:

\begin{lstlisting}
my_data <- data.frame(Sample1 = rnorm(100),
                      Sample2 = rnorm(100),
                      Sample3 = rnorm(100),
                      Sample4 = rnorm(100),
                      Sample5 = rnorm(100))
boxplot(my_data)
\end{lstlisting}

\subsubsection{Bar Plots and Pie Charts}

Now let's say that we have a data set that shows the number of called
peaks from a ChIPseq data set that fall into distinct genomic features
(exons, introns, promoters and intergenic regions). One way to look at
how the peaks fall would be to look at a pie graph:

\begin{lstlisting}
my_peak_nums <- c("exon" = 1400, "intron" = 900, "promoter" = 200, "intergenic" = 150)
pie(my_peak_nums)
\end{lstlisting}

This figure shows that the majority of the peaks fall into
exons. However, pie graphs are typically discouraged, because your
eyes can often make false estimates of the area taken up by each
feature. A better way of looking at data such as this would be in the
form of a barplot:

\begin{lstlisting}
barplot(my_peak_nums, ylab = "Number of Peaks in Feature", main = "Peaks in Gene Features")
\end{lstlisting}

Now let's suppose that we had data showing the number of peaks in
different genomic features for multiple samples. We could plot
multiple pie charts:

\begin{lstlisting}
my_peak_nums <- data.frame(GeneFeature = c("exon", "intron", "promoter", "intergenic"),
                           Sample1     = c( 1400,    900,       200,         150     ),
                           Sample2     = c( 2400,    1000,      230,         250     ),
                           Sample3     = c(  40,      30,       5,            7      )
                           )
par(mfrow = c(1,3))
pie(my_peak_nums[[2]], main = "Sample1", labels = my_peak_nums[[1]])
pie(my_peak_nums[[3]], main = "Sample2", labels = my_peak_nums[[1]])
pie(my_peak_nums[[4]], main = "Sample3", labels = my_peak_nums[[1]])
par(mfrow = c(1,1))  ## Reset the plotting region
\end{lstlisting}

However comparing across multiple pie charts is very
difficult. Instead, a single barplot will work better. Note that here
the number of peaks is different for each sample, so it makes more
sense to convert the data into a format whereby the bar height
represents the percentage of peaks within a particular feature:

\begin{lstlisting}
## Convert to percentages so that the samples are comparable
my_peak_percent <- my_peak_nums[, 2:4]
for (i in 1:3) {
  my_peak_percent[[i]] <- 100*my_peak_percent[[i]]/sum(my_peak_percent[[i]])
}

## Convert to a matrix to satisfy requirements for barplot()
my_peak_percent <- as.matrix(my_peak_percent)

## Plot the bar plot
barplot(my_peak_percent, 
        ylab        = "Percentage of Peaks in Feature", 
        main        = "Peaks in Gene Features", 
        legend.text = my_peak_nums[["GeneFeature"]])
\end{lstlisting}

Notice that the default way that \texttt{barplot()} works is to plot
the bars in a single stack for each sample. This is fine for comparing
the exons, but trying to compare the other classes is much harder. A
better way to plot these data would be to plot the bars side by side
for each sample:

\begin{lstlisting}
## Plot the bar plot
barplot(my_peak_percent, 
        ylab        = "Percentage of Peaks in Feature", 
        main        = "Peaks in Gene Features", 
        legend.text = my_peak_nums[["GeneFeature"]],
        beside      = TRUE)
\end{lstlisting}

\subsubsection{Graphical Control}

That covers the majority of the basic plotting functions that you may
want to use. You can change the standard plotting arguments by using the
\texttt{par()} command:

\begin{lstlisting}
par(mar = c(5,10,0,3)) ## Sets the figure margins (in 'number of lines') - b,l,t,r
par(las = 1)           ## Changes axis labels to always be horizontal
plot(x = rnorm(100), y = rnorm(100))
\end{lstlisting}

\subsubsection{Subplots}

By default, the graphics device will plot a single figure only. There
are several ways to create subfigures within this region. The first is
to set the \texttt{mfrow} argument. This will
split the graphics region into equally sized subplots:

\begin{lstlisting}
par(mfrow = c(3, 2))  ## Creates a figure region with 3 rows and 2 columns
for (i in 1:6) {
  plot(x = rnorm(100), y = rnorm(100))
}
\end{lstlisting}

However, if you want more control over your plotting, you can use the
\texttt{layout()} function which allows you to specify the size of the
subplots. This function takes a matrix specifying where in the grid of
subplots each plot should be drawn to. So the first call to
\texttt{plot()} will put its figure in the grid regions labelled '1',
the scond call will put its figure anywhere that there is a '2',
etc. Anywhere that you do not want a figure should have a '0'. The
\texttt{heights} and \texttt{widths} arguments allow you to specify
the size of each grid region. You can check what the resulting figure
layout will look like by using \texttt{layout.show(n)}, where 'n' is
the number of subplots in your figure. With a bit of work, you can get
some very good layouts: 

\begin{lstlisting}
## Same as using mfrow
layout(matrix(1:6, ncol = 2, nrow = 3, byrow = TRUE))
layout.show(6)
for (i in 1:6) {
  plot(x = rnorm(100), y = rnorm(100))
}

## More complex layout
my_layout <- matrix(c(1,1,1,1,2,2,3,4,2,2,3,4,0,0,3,4,0,0,5,5), 
                    nrow = 5, ncol = 4, byrow = TRUE)
layout(my_layout, widths = c(10,10,2,2), heights = c(1,5,5,5,2))
my_layout
layout.show(5)  ## Can you see how this matrix leads to this layout?
layout(1) ## Reset plotting region
\end{lstlisting}

\subsubsection{Saving Figures}

By default, figures are generated in a seperate window from
R. However, you can save the figure to an external file by using one
of the functions ``png()'', ``pdf()'', ``jpeg()'', etc. These
functions open a new ``device'', which R can use to plot to. After the
figure has been plotted, the device must be turned off again using the
``dev.off()'' function. There are many arguments that can be used for
these functions. In general, these define the dimensions and
resolution of the resulting figure. It can be difficult to get these
right, so play around to see how they affect things:

\begin{lstlisting}
png("test_figure.png", height = 10, width = 10, unit = "in", res = 300)
plot(1:10, 1:10, type = "l", main = "My Test Figure", xlab = "x axis", ylab = "y axis")
dev.off()
\end{lstlisting}


\subsection{Example Analysis}

\subsubsection{Introduction}
This is just a simple example analysis to give you an idea of the sort
of things that we can do with R. Suppose that we have two experiments,
each looking at the effects on gene expression of using a particular
drug (``Drug A'' and ``Drug B''). For each experiment we have two samples; one showing the gene
expression when treated with the drug, and the other showing the gene
expression when treated with some control agent. Obviously in a real
experiment, we would have many replicates, but here we have n=1. 
We want to do the following:

\begin{enumerate}
  \item For each drug, we want to get the fold change for each gene
  \item For each drug, we want to identify the genes that are
    significantly changed when using the drug
  \item We want to compare the results for Drug A with those from Drug
    B to find genes that are affected similarly by both drugs
  \item We want to plot the correlation between the fold change values
    for the two drugs to see how similar they are
\end{enumerate}

For this, we will need four files. These files are in a tab delimited
format. They are tables of values where each row is separated by a new
line, and each column is separated by a tab character
(\verb:"\t":). These files can be created by and read into Excel for
ease of use. To avoid errors when reading in files from text, it is
good practice to ensure that there are no missing cells in your
data. Instead try to get into the habit of using some 'missing'
character (e.g. ``NA'').

\begin{description}
  \item [experiment1\_control.txt] Contains gene expression levels for
    control sample from experiment 1 
  \item [experiment1\_drug.txt] Contains gene expression levels for
    sample treated with drug A in experiment 1
  \item [experiment2\_control.txt] Contains gene expression levels for
    control sample from experiment 2
  \item [experiment2\_drug.txt]Contains gene expression levels for
    sample treated with drug B in experiment 2
\end{description}

\subsubsection{Load Data}

First let's load in the data:

\begin{lstlisting}
expt1_ctrl <- read.table("experiment1_control.txt", header = TRUE, sep = "\t",
                         stringsAsFactors = FALSE)
expt1_drug <- read.table("experiment1_drug.txt",    header = TRUE, sep = "\t",
                         stringsAsFactors = FALSE)
expt2_ctrl <- read.table("experiment2_control.txt", header = TRUE, sep = "\t",
                         stringsAsFactors = FALSE)
expt2_drug <- read.table("experiment2_drug.txt",    header = TRUE, sep = "\t",
                         stringsAsFactors = FALSE)
\end{lstlisting}

Use \texttt{head()} to look at the data. Each of these files contains
two columns. The gene name and some value that represents the
expression level for that gene (assume that these values have been
calculated after pre-processing, normalisation, etc.). 

In all of these cases, the list of gene names is identical, and in the
same order which means that we could compare row 1 from the control-treated
file with row 2 from the drug-treated file to get all of the
comparisons. However, in a real data set you will not know for sure
that the gene names match so I recommend merging the files together
into a single data frame to ensure that all analyses are conducted on
a gene by gene basis on the correct values. We therefore create a
single data frame for both experiments using the \texttt{merge()}
command:

\begin{lstlisting}
expt1 <- merge(expt1_ctrl, expt1_drug, by = "GeneName") ## The 'by' variable tells merge which column to merge 
names(expt1)[2] <- "Control" ## Make sure that the columns are correctly labelled
names(expt1)[3] <- "Drug"    ## Make sure that the columns are correctly labelled
expt2 <- merge(expt2_ctrl, expt2_drug, by = "GeneName") ## The 'by' variable tells merge which column to merge 
names(expt2)[2] <- "Control" ## Make sure that the columns are correctly labelled
names(expt2)[3] <- "Drug"    ## Make sure that the columns are correctly labelled
\end{lstlisting}

\subsubsection{Calculate Fold Change}

Now we calculate the fold change for each gene by dividing the
drug-treated expression by the control expression. To avoid divide by
zero errors, we can set a minimum expression value. This will also
ensure that we are only looking at expression changes between
significant expression values. Since we want to do the same thing to
both the experiment 1 and the experiment 2 data sets, it makes sense
to write a single function to use for both:

\begin{lstlisting}
## Function to get the fold change for a single gene
get_fold_change <- function (x, min_expression = 10) {

  ## Get the control and drug-treated values (must explicitly convert them to be numeric)
  ctrl_val <- as.numeric(x["Control"])
  drug_val <- as.numeric(x["Drug"])

  ## Ensure values are at least as great as the minimum
  ctrl_val <- ifelse(ctrl_val <= min_expression, min_expression, ctrl_val)
  drug_val <- ifelse(drug_val <= min_expression, min_expression, drug_val)

  ## Return the fold change
  return(drug_val/ctrl_val)
}

## Get the fold change for each experiment
expt1[["FoldChange"]] <- apply(expt1, MAR = 1, FUN = get_fold_change)
expt2[["FoldChange"]] <- apply(expt2, MAR = 1, FUN = get_fold_change)
\end{lstlisting}

\subsubsection{Compare Data}

Now let's find the genes that are upregulated and downregulated in
each experiment. Due to the lack of replicates, we do not have any
estimate for the variance of these genes, so we will have to make do
with using a threshold on the fold change:

\begin{lstlisting}
## Set the fold change threshold
fold_change_threshold <- 1.5

## Get the changing genes for experiment 1
expt1_up   <- subset(expt1, FoldChange >= fold_change_threshold)[["GeneName"]]
expt1_down <- subset(expt1, FoldChange <= 1/fold_change_threshold)[["GeneName"]]

## Get the changing genes for experiment 2
expt2_up   <- subset(expt2, FoldChange >= fold_change_threshold)[["GeneName"]]
expt2_down <- subset(expt2, FoldChange <= 1/fold_change_threshold)[["GeneName"]]

## Output the results
cat("Upregulated in Experiment 1:",   
    paste(expt1_up,   collapse = "\n"), sep = "\n")
cat("Downregulated in Experiment 1:", 
    paste(expt1_down, collapse = "\n"), sep = "\n")
cat("Upregulated in Experiment 2:",   
    paste(expt2_up,   collapse = "\n"), sep = "\n")
cat("Downregulated in Experiment 2:", 
    paste(expt2_down, collapse = "\n"), sep = "\n")
\end{lstlisting}

So we now have the genes that change when each of the drugs is
used. But now we want to compare the two drugs together. First, let's
see if there are any genes similarly affected by both drugs. We can do
this using the \texttt{intersect()} function which gives the intersect
of two lists:

\begin{lstlisting}
## Find any common genes
common_up   <- intersect(expt1_up,   expt2_up)
common_down <- intersect(expt1_down, expt2_down)

## Output the results
cat("Upregulated in Experiment 1 and Experiment 2:",   paste(common_up,   collapse = "\n"), sep = "\n")
cat("Downregulated in Experiment 1 and Experiment 2:", paste(common_down, collapse = "\n"), sep = "\n")
\end{lstlisting}

So we can see that only one gene is similarly affected by both drugs
(``gene8''). Now let's plot a figure to see how the fold change
differs between the two drugs:

\begin{lstlisting}
## Merge the two data sets
fold_change_data <- merge(expt1[, c("GeneName", "FoldChange")], expt2[, c("GeneName", "FoldChange")], by = "GeneName")
names(fold_change_data)[2] <- "Experiment1"
names(fold_change_data)[3] <- "Experiment2"

## Plot the data (use log to see downregulated genes better)
plot(x = log2(fold_change_data[["Experiment1"]]),
     y = log2(fold_change_data[["Experiment2"]]),
     pch = 19,                                                     ## Changes the point type
     xlab = "log2(Experiment1 Fold Change)",                       ## Label x axis
     ylab = "log2(Experiment2 Fold Change)",                       ## Label y axis
     main = "Experiment1 Fold Change vs Experiment2 Fold Change",  ## Main figure title
     cex.lab = 1.3,                                                ## Increase axis labels
     cex.axis = 1.2,                                               ## Increase value labels
     cex.main = 1.4,                                               ## Increase size of title
     xlim = c(-2,2),                                               ## Set x-axis limits
     ylim = c(-2,2)                                                ## Set y-axis limits
     )

## Add horizontal and vertical lines through the origin
abline(h = 0)
abline(v = 0)

## Add an x = y line
abline(a = 0, b = 1, lty = 2)
\end{lstlisting}

This figure shows that the effect on the gene expression is actually
quite different for the two drugs. We can also see this by looking at
the correlation between the two experiments:

\begin{lstlisting}
cor(x      = fold_change_data[["Experiment1"]], 
    y      = fold_change_data[["Experiment2"]], 
    method = "pearson")
cor(x      = fold_change_data[["Experiment1"]], 
    y      = fold_change_data[["Experiment2"]], 
    method = "spearman")
\end{lstlisting}


\end{document}